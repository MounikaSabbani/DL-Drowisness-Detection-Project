{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os.path\n",
    "from imutils import face_utils\n",
    "from imutils.video import FPS\n",
    "from moviepy.editor import VideoFileClip\n",
    "from imutils.video import FileVideoStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-d\", \"--directory\", help=\"path to start from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read arguments from the command line\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.directory:\n",
    "    print(args.directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_haar = os.path.join('build','etc','haarcascades')\n",
    "path_pred_5  = os.path.join('facial-landmarks','shape_predictor_5_face_landmarks.dat')\n",
    "path_pred_68 = os.path.join('facial-landmarks','shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pred = path_pred_68\n",
    "landmark_pts_count = 68\n",
    "\n",
    "header = ['participant', 'mood', 'fps', \n",
    "          'size_x', 'size_y', \n",
    "          'frame_no', 'time', 'face_x','face_y','face_w','face_h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 350\n",
    "progress_report = None\n",
    "\n",
    "csv_output_path = os.path.join('.', 'output', 'csv')\n",
    "report_output_path = os.path.join('.', 'output', 'report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(os.path.join(path_haar, 'haarcascade_frontalface_default.xml'))\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(path_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Table Header\n",
    "for i in range(landmark_pts_count):\n",
    "    header.append('px_'+str(i+1))\n",
    "    header.append('py_'+str(i+1))\n",
    "\n",
    "final_list = []\n",
    "final_list.append(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in [csv_output_path, report_output_path]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class participent:\n",
    "    def __init__(self, participent, location):\n",
    "        self.location = location\n",
    "        self.participant_no = participent\n",
    "\n",
    "        \n",
    "    def get_video_metadata(self, video_path):\n",
    "        c = VideoFileClip(video_path)\n",
    "        rotation = c.rotation\n",
    "        fps = c.fps\n",
    "        if rotation in [0,180]:\n",
    "            size_x = c.size[0]\n",
    "            size_y = c.size[1]\n",
    "        else:\n",
    "            size_x = c.size[1]\n",
    "            size_y = c.size[0]\n",
    "        c.close()\n",
    "        \n",
    "        print(rotation, fps, size_x, size_y)\n",
    "        return rotation, fps, size_x, size_y\n",
    "       \n",
    "        \n",
    "    def process_all_moods(self, width, progress_report):\n",
    "        #Find all that needs processesing\n",
    "        videos = glob.glob(os.path.join(self.location,'*'))\n",
    "        for video_path in videos:\n",
    "            print(f\"Path: {video_path}\")\n",
    "            try:\n",
    "                self.process_one_mood(video_path, width, progress_report)\n",
    "            except Exception as  e:\n",
    "                print(f\"failed processing {video_path}: {e}\")\n",
    "                traceback.print_tb(e.__traceback__)\n",
    "\n",
    "        \n",
    "    def process_one_mood(self, video_path, width, progress_report):\n",
    "        # Reporting results\n",
    "        dropped_frames = []\n",
    "        \n",
    "        # Metadata\n",
    "        video_rotation, video_fps, size_x, size_y = self.get_video_metadata(video_path)\n",
    "        print(\"rotation: \", video_rotation)\n",
    "        print(\"fps: \", video_fps)\n",
    "        print(\"size_x: \", size_x)\n",
    "        print(\"size_y: \", size_y)\n",
    "        \n",
    "        assert(video_fps != 0)         \n",
    "\n",
    "        mood = os.path.basename(video_path).split('.')[0]\n",
    "        frame_len = 1/video_fps\n",
    "        \n",
    "        print(\"[INFO] starting video file thread...\")\n",
    "        fvs = FileVideoStream(video_path).start()\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        time.sleep(1.0)\n",
    "\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "\n",
    "        # variables\n",
    "        #result_df = pd.DataFrame(columns=header, \n",
    "        #data=np.empty(shape=(total_frames-1, len(header))))\n",
    "        result_np = np.empty(shape=(total_frames-1, len(header)))\n",
    "     \n",
    "        fps = FPS().start()\n",
    "        frame_no = 0\n",
    "        for i in range(frame_no, total_frames - 1):\n",
    "            frame_row = []\n",
    "            assert(fvs.more())\n",
    "            frame = fvs.read()\n",
    "            assert(frame is not None)\n",
    "            \n",
    "            frame = imutils.rotate_bound(frame, video_rotation)\n",
    "            frame = imutils.resize(frame, width=width)\n",
    "            \n",
    "            frame_row.append(self.participant_no)\n",
    "            frame_row.append(mood)\n",
    "            frame_row.append(video_fps)\n",
    "            frame_row.append(size_x)\n",
    "            frame_row.append(size_y)\n",
    "            \n",
    "            frame_row.append(frame_no)\n",
    "            frame_row.append(frame_no*frame_len)\n",
    "            \n",
    "            if progress_report is not None:\n",
    "                if (frame_no % progress_report) == 0: \n",
    "                    print(\"processing frame: \", frame_no)\n",
    "          \n",
    "            frame_row += self.process_frame(frame)\n",
    "            # result_df.iloc[frame_no] = frame_row\n",
    "            result_np[frame_no] = frame_row\n",
    "            if '-1' in frame_row: \n",
    "                dropped_frames.append(frame_no)\n",
    "            \n",
    "            \n",
    "            # Press Q on keyboard to  exit \n",
    "            # if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "            #break\n",
    "        \n",
    "            frame_no += 1\n",
    "            fps.update()\n",
    "            \n",
    "        fps.stop()\n",
    "        print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "        print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "        fvs.stop()\n",
    "        \n",
    "        # Process one mood\n",
    "        # display if needed\n",
    "        result_df = pd.DataFrame(columns=header, data=result_np)\n",
    "        result_df.to_csv(os.path.join(csv_output_path, f\"{self.participant_no}_{mood}.csv\"))\n",
    "        \n",
    "        with open(os.path.join(report_output_path, f\"{self.participant_no}_{mood}.txt\"),\"w\") as report:\n",
    "            report.write(f\"video: {video_path}\\n\")\n",
    "            report.write(f\"metadata: {video_fps} fps, {video_rotation} deg, {size_x}x{size_y}\")\n",
    "            report.write(f\"dropped: {dropped_frames}\\n\")\n",
    "            report.write(\"elasped time: {:.2f}\\n\".format(fps.elapsed()))\n",
    "            report.write(\"approx. FPS: {:.2f}\\n\".format(fps.fps()))\n",
    "            \n",
    "            report.write(\"-\"*20)\n",
    "        # Save to df\n",
    "        pass\n",
    "    \n",
    "    def process_frame(self, frame):\n",
    "        return_list = []\n",
    "        # reads frames from a camera \n",
    "        img = frame  \n",
    "      \n",
    "        # convert to gray scale of each frames \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "      \n",
    "        \n",
    "        #CV2\n",
    "        # faces = face_cascade.detectMultiScale(gray, 1.2, 5) \n",
    "        # for (x,y,w,h) in faces: \n",
    "        # DLIB2\n",
    "        rects = detector(gray, 0)\n",
    "        if len(rects) == 0:\n",
    "            return_list = ['-1' for x in range(4+(landmark_pts_count*2))]\n",
    "        if len(rects) > 1 : \n",
    "            rects = [rects[0]]\n",
    "        \n",
    "        for (x,y,w,h) in [face_utils.rect_to_bb(x) for x in rects]:\n",
    "            return_list += [x, y, w, h]\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)  \n",
    "            roi_gray = gray[y:y+h, x:x+w] \n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            \n",
    "            shape_img = dlib.rectangle(int(x), int(y), int(x+w), int(y+h))\n",
    "            shape = predictor(img, shape_img)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            # loop over the (x, y)-coordinates for the facial landmarks\n",
    "            # and draw them on the image\n",
    "            if len(shape) ==0:\n",
    "                return_list += ['-1' for x in range(landmark_pts_count * 2)]\n",
    "            else:    \n",
    "                assert(len(shape) == landmark_pts_count)\n",
    "                return_list += [item for sublist in shape.tolist() for item in sublist]\n",
    "    \n",
    "            \n",
    "        # Display an image in a window \n",
    "        #cv2.imshow('img',img) \n",
    "        #cv2.imshow('gray cut',roi_gray) \n",
    "        if not (len(return_list) == landmark_pts_count * 2 + 4):\n",
    "            print(f\"len{len(return_list)}\")\n",
    "            print(f'{return_list}')\n",
    "        return return_list\n",
    "    \n",
    "\n",
    "## Find all folders\n",
    "if args.directory:\n",
    "    filesDepth3 = glob.glob(os.path.join(args.directory,'*'))\n",
    "else:\n",
    "    filesDepth3 = glob.glob(os.path.join('raw_data','*'))\n",
    "dirsDepth3 = filter(lambda f: os.path.isdir(f), filesDepth3)\n",
    "\n",
    "    \n",
    "def run_participant(path):\n",
    "    print(\"processing\", path)\n",
    "    p_no = (os.path.basename(path))\n",
    "    p = participent(p_no, path)\n",
    "    p.process_all_moods(width, progress_report)\n",
    "    \n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "print(\"start pooling\")\n",
    "pool = ThreadPool(4) \n",
    "print(\"Started\")\n",
    "#print([x for x in dirsDepth3])\n",
    "results = pool.map(run_participant, dirsDepth3)\n",
    "print(results)\n",
    "\n",
    "# close the pool and wait for the work to finish \n",
    "pool.close() \n",
    "pool.join() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
